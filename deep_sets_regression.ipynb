{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_sets_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyV1xOy7YpvVFYo+nA9/6K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neelamku/DNN-ttH/blob/main/deep_sets_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy1dDYwlddgz"
      },
      "source": [
        "!pip install uproot3\n",
        "!pip install uproot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qInLIWgMdqK8",
        "outputId": "cb4dd72d-8b82-448e-abc6-77290c2b62d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LJkbOtddqmM"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "import uproot3\n",
        "import uproot\n",
        "\n",
        "#root to arrays\n",
        "\n",
        "tree = uproot3.open(\"/content/drive/MyDrive/Colab Notebooks/rnn_comb.root\")[\"nominal_Loose_new\"]\n",
        "tree1 = uproot3.open(\"/content/drive/MyDrive/Colab Notebooks/rnn_rewg_latest.root\")[\"nominal_Loose_new\"]\n",
        "\n",
        "m_truthpt_weights = tree1[\"truthpt_weights\"].array()\n",
        "\n",
        "m_higgs_truthPt = tree[\"higgs_truthPt\"].array()\n",
        "m_comb_higgs_truthPt = tree[\"comb_higgs_truthPt\"].array()\n",
        "m_best_higgs_Pt = tree[\"best_higgs_Pt\"].array()\n",
        "m_comb_best_higgs_Pt = tree[\"comb_best_higgs_Pt\"].array()\n",
        "m_best_higgs_Pt_withH = tree[\"best_higgs_Pt_withH\"].array()\n",
        "m_comb_best_higgs_Pt_withH = tree[\"comb_best_higgs_Pt_withH\"].array()\n",
        "\n",
        "m_nBTags_DL1r85 = tree[\"nBTags_DL1r85\"].array()\n",
        "m_nBTags_DL1r70 = tree[\"nBTags_DL1r70\"].array()\n",
        "\n",
        "m_higgs_pt = tree[\"comb_higgs_pt\"].array()\n",
        "m_higgs_mass = tree[\"comb_higgs_mass\"].array()\n",
        "m_hadW_mass = tree[\"comb_hadW_mass\"].array()\n",
        "m_hadtop_mass = tree[\"comb_hadtop_mass\"].array()\n",
        "m_leptop_mass = tree[\"comb_leptop_mass\"].array()\n",
        "m_hadWblepTop_mass = tree[\"comb_hadWblepTop_mass\"].array()\n",
        "m_minbhadTopqhadW_dR = tree[\"comb_minbhadTopqhadW_dR\"].array()\n",
        "m_hadWblepTop_dR = tree[\"comb_hadWblepTop_dR\"].array()\n",
        "m_blepTopbhadTop_dR = tree[\"comb_blepTopbhadTop_dR\"].array()\n",
        "m_bhadTopq2hadW_dR = tree[\"comb_bhadTopq2hadW_dR\"].array()\n",
        "m_hadWbhadTop_dR = tree[\"comb_hadWbhadTop_dR\"].array()\n",
        "m_Higgsq1hadW_mass = tree[\"comb_Higgsq1hadW_mass\"].array()\n",
        "m_bbHiggs_dR = tree[\"comb_bbHiggs_dR\"].array()\n",
        "m_bhadTopq1hadW_dR = tree[\"comb_bhadTopq1hadW_dR\"].array()\n",
        "m_qqhadW_dR = tree[\"comb_qqhadW_dR\"].array()\n",
        "m_diff_mindRbhadTopqhadW_dRlepblepTop = tree[\"comb_diff_mindRbhadTopqhadW_dRlepblepTop\"].array()\n",
        "m_lepbhadTop_dR = tree[\"comb_lepbhadTop_dR\"].array()\n",
        "m_lepb1Higgs_dR = tree[\"comb_lepb1Higgs_dR\"].array()\n",
        "m_lepWbhadTop_mass = tree[\"comb_lepWbhadTop_mass\"].array()\n",
        "m_lepblepTop_dR = tree[\"comb_lepblepTop_dR\"].array()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InYwpWXodshg",
        "outputId": "c6bf0ac8-8b77-4751-d4cd-93584027bf66"
      },
      "source": [
        "#prepare data###\n",
        "\n",
        "in_higgs_truthPt = []\n",
        "in_best_higgs_Pt_withH = []\n",
        "\n",
        "#20 variables for input\n",
        "\n",
        "varList = []\n",
        "in_higgs_pt = []\n",
        "in_higgs_mass = []\n",
        "in_hadW_mass = []\n",
        "in_hadtop_mass = []\n",
        "in_leptop_mass = []\n",
        "in_hadWblepTop_mass = []\n",
        "in_minbhadTopqhadW_dR = []\n",
        "in_hadWblepTop_dR = []\n",
        "in_blepTopbhadTop_dR = []\n",
        "in_bhadTopq2hadW_dR = []\n",
        "in_hadWbhadTop_dR = []\n",
        "in_Higgsq1hadW_mass = []\n",
        "in_bbHiggs_dR = []\n",
        "in_bhadTopq1hadW_dR = []\n",
        "in_qqhadW_dR = []\n",
        "in_diff_mindRbhadTopqhadW_dRlepblepTop = []\n",
        "in_lepbhadTop_dR = []\n",
        "in_lepb1Higgs_dR = []\n",
        "in_lepWbhadTop_mass = []\n",
        "in_lepblepTop_dR = []\n",
        "\n",
        "\n",
        "### BTag selections\n",
        "in_nBTags_DL1r85 = []\n",
        "in_nBTags_DL1r70 = []\n",
        "\n",
        "### Truth pT weights\n",
        "in_truthpt_weights = []\n",
        "\n",
        "### count \n",
        "pass_no = 0\n",
        "count = []\n",
        "\n",
        "### put selections and fill only those events\n",
        "\n",
        "for i in range(0,len(m_higgs_truthPt)):\n",
        "  if (m_higgs_truthPt[i]>0): \n",
        "   if (m_nBTags_DL1r70[i]>=4):\n",
        "    if (len(m_higgs_pt[i])>0): #select events with 12/24 combinations\n",
        "\n",
        "      pass_no = pass_no + 1\n",
        "      count.append(pass_no)\n",
        "\n",
        "      ###fill inputs here\n",
        "\n",
        "      in_higgs_truthPt.append(m_higgs_truthPt[i])\n",
        "      in_best_higgs_Pt_withH.append(m_best_higgs_Pt_withH[i])\n",
        "  \n",
        "      ###\n",
        "\n",
        "      in_higgs_pt.append(m_higgs_pt[i])\n",
        "      in_higgs_mass.append(m_higgs_mass[i])\n",
        "      in_hadW_mass.append(m_hadW_mass[i])\n",
        "      in_hadtop_mass.append(m_hadtop_mass[i])\n",
        "      in_leptop_mass.append(m_leptop_mass[i])\n",
        "      in_hadWblepTop_mass.append(m_hadWblepTop_mass[i])\n",
        "      in_minbhadTopqhadW_dR.append(m_minbhadTopqhadW_dR[i])\n",
        "      in_hadWblepTop_dR.append(m_hadWblepTop_dR[i])\n",
        "      in_blepTopbhadTop_dR.append(m_blepTopbhadTop_dR[i])\n",
        "      in_bhadTopq2hadW_dR.append(m_bhadTopq2hadW_dR[i])\n",
        "      in_hadWbhadTop_dR.append(m_hadWbhadTop_dR[i])\n",
        "      in_Higgsq1hadW_mass.append(m_Higgsq1hadW_mass[i])\n",
        "      in_bbHiggs_dR.append(m_bbHiggs_dR[i])\n",
        "      in_bhadTopq1hadW_dR.append(m_bhadTopq1hadW_dR[i])\n",
        "      in_qqhadW_dR.append(m_qqhadW_dR[i])\n",
        "      in_diff_mindRbhadTopqhadW_dRlepblepTop.append(m_diff_mindRbhadTopqhadW_dRlepblepTop[i])\n",
        "      in_lepbhadTop_dR.append(m_lepbhadTop_dR[i])\n",
        "      in_lepb1Higgs_dR.append(m_lepb1Higgs_dR[i])\n",
        "      in_lepWbhadTop_mass.append(m_lepWbhadTop_mass[i])\n",
        "      in_lepblepTop_dR.append(m_lepblepTop_dR[i])\n",
        "         \n",
        "      ###\n",
        "      \n",
        "      in_truthpt_weights.append(m_truthpt_weights[i])\n",
        "\n",
        "a1 = len(count)\n",
        "print (a1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "73094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMlXcnIPdumX",
        "outputId": "00fef6fb-9d29-4748-f520-88642966628c"
      },
      "source": [
        "#make fixed length for inputs\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "varOrder = [in_higgs_pt,in_higgs_mass,in_hadW_mass,in_hadtop_mass,in_leptop_mass,in_hadWblepTop_mass,in_minbhadTopqhadW_dR,in_hadWblepTop_dR,in_blepTopbhadTop_dR,in_bhadTopq2hadW_dR,in_hadWbhadTop_dR,in_Higgsq1hadW_mass,in_bbHiggs_dR,in_bhadTopq1hadW_dR,in_qqhadW_dR,in_diff_mindRbhadTopqhadW_dRlepblepTop,in_lepbhadTop_dR,in_lepb1Higgs_dR,in_lepWbhadTop_mass,in_lepblepTop_dR]\n",
        "padded_input = []\n",
        "\n",
        "for j in range(0,len(varOrder)):\n",
        "  padded_input.append(tf.keras.preprocessing.sequence.pad_sequences(varOrder[j], padding=\"post\",dtype='float32'))\n",
        "\n",
        "X_sig = np.array(padded_input)\n",
        "X_sig_all_input = np.transpose(X_sig, (1, 2, 0))\n",
        "print (X_sig_all_input.shape)\n",
        "\n",
        "#mask zero from normalization\n",
        "#uncomment if normalize\n",
        "\n",
        "nz = np.any(X_sig_all_input, -1)\n",
        "X_sig_all_input[nz] = StandardScaler().fit_transform(X_sig_all_input[nz])\n",
        "\n",
        "#print(X_sig_all_input[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(73094, 24, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zT14AQpldwWO",
        "outputId": "2e0f4df3-b339-450c-9f45-069a45bd082b"
      },
      "source": [
        "##target\n",
        "Y_sig = np.copy(in_higgs_truthPt)\n",
        "print (Y_sig.shape)\n",
        "\n",
        "## best higgs pT\n",
        "X_sig_best_higgs_pt_withH = np.copy(in_best_higgs_Pt_withH)\n",
        "\n",
        "##weights\n",
        "rewg_weights = np.copy(in_truthpt_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(73094,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeKkg1o1d0M2",
        "outputId": "12122d12-dd3d-4888-b94b-83d716a6f584"
      },
      "source": [
        "##split data: train and test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#signal 01\n",
        "X_train_all_input, X_test_all_input, Y_train_01, Y_test_01 =  train_test_split(X_sig_all_input, Y_sig, test_size=0.50, random_state=42 )\n",
        "print (X_train_all_input.shape)\n",
        "\n",
        "#signal 02 for checks only\n",
        "X_train_best_higgs_pt_withH, X_test_best_higgs_pt_withH, Y_train_02, Y_test_02 =  train_test_split(X_sig_best_higgs_pt_withH, Y_sig, test_size=0.50, random_state=42 )\n",
        "print (X_train_best_higgs_pt_withH.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(36547, 24, 20)\n",
            "(36547,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ9IslYsd2Oy",
        "outputId": "408efb44-c764-4b1e-a6f2-a5895f5fee21"
      },
      "source": [
        "## import functions\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.layers import BatchNormalization, Layer, TimeDistributed, Dropout\n",
        "from keras.layers import Dense, Input, ReLU, Masking, LSTM, Embedding, Lambda, Bidirectional, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "import statsmodels.api as sm\n",
        "\n",
        "#from numpy.random import seed\n",
        "#seed(1)\n",
        "#import tensorflow\n",
        "#tensorflow.random.set_seed(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lljj5bi-d5rg"
      },
      "source": [
        "###deep set model\n",
        "\n",
        "class Sum(Layer):\n",
        "  \n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        pass\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        if mask is not None:\n",
        "            x = x * K.cast(mask, K.dtype(x))[:,:,None]\n",
        "        return K.sum(x, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[2]\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN_y2nNQd8lk"
      },
      "source": [
        "nEvnt, nComb, nFeatures = X_train_all_input.shape\n",
        "ppm_sizes_int = [100,100,128]\n",
        "dense_sizes_int = [100,100,100]\n",
        "\n",
        "batch_norm = True\n",
        "dropout = 0\n",
        "nClasses = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHYBcuu_eLM_",
        "outputId": "a4dee273-201c-46ee-b1e3-00847fc3f4ea"
      },
      "source": [
        "in_inputs = Input(shape=(nComb,nFeatures))\n",
        "masked_inputs = Masking(mask_value=0)(in_inputs)\n",
        "tdd = masked_inputs\n",
        "\n",
        "for i, phi_nodes in enumerate(ppm_sizes_int):\n",
        "\n",
        "    tdd = TimeDistributed(Dense(phi_nodes,activation='relu'),name=\"Phi{}_Dense\".format(i))(tdd)\n",
        "    if batch_norm:\n",
        "        tdd = TimeDistributed(BatchNormalization(),name=\"Phi{}_BatchNormalization\".format(i))(tdd)\n",
        "    if dropout != 0:\n",
        "        tdd = TimeDistributed(Dropout(rate=dropout),name=\"Phi{}_Dropout\".format(i))(tdd)\n",
        "    tdd = TimeDistributed(ReLU(),name=\"Phi{}_ReLU\".format(i))(tdd)\n",
        "\n",
        "F = Sum(name=\"Sum\")(tdd)\n",
        "\n",
        "for j, (F_nodes, p) in enumerate(zip(dense_sizes_int,\n",
        "                                 [dropout]*len(dense_sizes_int[:-1])+[0])):\n",
        "\n",
        "    F = Dense(F_nodes, activation='relu', name=\"F{}_Dense\".format(j))(F)\n",
        "    if batch_norm:\n",
        "        F = BatchNormalization(name=\"F{}_BatchNormalization\".format(j))(F)\n",
        "    if dropout != 0:\n",
        "        F = Dropout(rate=p,name=\"F{}_Dropout\".format(j))(F)\n",
        "    F = ReLU(name=\"F{}_ReLU\".format(j))(F)\n",
        "\n",
        "output = Dense(nClasses, activation='linear',name=\"Output\")(F)\n",
        "model = Model(inputs=in_inputs, outputs=output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 24, 20)]          0         \n",
            "_________________________________________________________________\n",
            "masking (Masking)            (None, 24, 20)            0         \n",
            "_________________________________________________________________\n",
            "Phi0_Dense (TimeDistributed) (None, 24, 100)           2100      \n",
            "_________________________________________________________________\n",
            "Phi0_BatchNormalization (Tim (None, 24, 100)           400       \n",
            "_________________________________________________________________\n",
            "Phi0_ReLU (TimeDistributed)  (None, 24, 100)           0         \n",
            "_________________________________________________________________\n",
            "Phi1_Dense (TimeDistributed) (None, 24, 100)           10100     \n",
            "_________________________________________________________________\n",
            "Phi1_BatchNormalization (Tim (None, 24, 100)           400       \n",
            "_________________________________________________________________\n",
            "Phi1_ReLU (TimeDistributed)  (None, 24, 100)           0         \n",
            "_________________________________________________________________\n",
            "Phi2_Dense (TimeDistributed) (None, 24, 128)           12928     \n",
            "_________________________________________________________________\n",
            "Phi2_BatchNormalization (Tim (None, 24, 128)           512       \n",
            "_________________________________________________________________\n",
            "Phi2_ReLU (TimeDistributed)  (None, 24, 128)           0         \n",
            "_________________________________________________________________\n",
            "Sum (Sum)                    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "F0_Dense (Dense)             (None, 100)               12900     \n",
            "_________________________________________________________________\n",
            "F0_BatchNormalization (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "F0_ReLU (ReLU)               (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "F1_Dense (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "F1_BatchNormalization (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "F1_ReLU (ReLU)               (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "F2_Dense (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "F2_BatchNormalization (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "F2_ReLU (ReLU)               (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 60,841\n",
            "Trainable params: 59,585\n",
            "Non-trainable params: 1,256\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jySZcfznpKF9"
      },
      "source": [
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "\n",
        "nEpochs = 2000\n",
        "\n",
        "earlyStop = EarlyStopping(monitor='val_loss', verbose=True, patience=10)\n",
        "\n",
        "ds_mChkPt = ModelCheckpoint('ds_weights.h5',monitor='val_loss', verbose=True,\n",
        "                              save_best_only=True,\n",
        "                              save_weights_only=True)\n",
        "\n",
        "ds_hist = model.fit(X_train_all_input, Y_train_01, epochs=nEpochs, batch_size=256,validation_split=0.2,\n",
        "                     callbacks=[earlyStop, ds_mChkPt])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhvEJrJPeXHk"
      },
      "source": [
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9uhzuPMeZco"
      },
      "source": [
        "#predictions\n",
        "\n",
        "ypred= model.predict(X_test_all_input,batch_size=128).flatten()\n",
        "print (ypred.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A95svlmmeZm3"
      },
      "source": [
        "epochs = np.arange(1,len(ds_hist.history['loss'])+1)\n",
        "\n",
        "plt.plot(epochs,ds_hist.history['loss'],label='training')\n",
        "plt.plot(epochs,ds_hist.history['val_loss'],label='validation')\n",
        "plt.xlim([0, len(ds_hist.history['loss'])+1])\n",
        "plt.xlabel('epochs',fontsize=14)\n",
        "plt.ylabel('mean squared loss',fontsize=14)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shJk1S-delJM"
      },
      "source": [
        "plt.xlabel('Higgs pT [GEV]')\n",
        "plt.hist(Y_test_01/1000, bins=np.linspace(0,600,60), color='gray', alpha=0.3, fill='tozeroy', hatch = '////',linewidth=2, label='test - Truth')\n",
        "#plt.hist(X_test_best_higgs_pt_withH/1000, bins=np.linspace(0,600,60),histtype='step', linewidth=2.5, label='test - RecoBDT')\n",
        "plt.hist(ypred/1000, bins=np.linspace(0,600,60),histtype='step', linewidth=2.5, label='test - RNN')\n",
        "plt.text(420,2800, r'6ji4bi@70%', fontsize=8)\n",
        "plt.text(420,2500, r'Normalized', fontsize=8)\n",
        "plt.title('All inputs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yVtxdoHeoPJ"
      },
      "source": [
        "plt.xlabel('Higgs pT [GEV]')\n",
        "plt.hist(Y_train_01/1000, bins=np.linspace(0,600,60), color='gray', alpha=0.3, fill='tozeroy', hatch = '////',linewidth=2, label='train - Truth')\n",
        "#plt.hist(X_train_best_higgs_pt_withH/1000, bins=np.linspace(0,600,60),histtype='step', linewidth=2.5, label='train - RecoBDT')\n",
        "plt.hist(ypred_train/1000, bins=np.linspace(0,600,60),histtype='step', linewidth=2.5, label='train - RNN')\n",
        "plt.text(420,2700, r'6ji4bi@70%', fontsize=8)\n",
        "plt.text(420,2500, r'Normalized', fontsize=8)\n",
        "plt.title('All inputs')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5XD9DtReqhO"
      },
      "source": [
        "sample2a = Y_test_01/1000-(ypred/1000)\n",
        "plt.xlabel('Truth - Predictions')\n",
        "\n",
        "plt.hist(sample2a, bins=50, density=True, histtype='step',linewidth=2.5,label='test - RNN')\n",
        "\n",
        "rms2a = np.sqrt(np.mean(sample2a**2))\n",
        "\n",
        "plt.title('')\n",
        "plt.xlim([-400, 400])\n",
        "plt.ylim([0, 0.008])\n",
        "plt.text(250,0.006, r'6ji4bi@70%', fontsize=8)\n",
        "plt.text(250,0.0055, r'Normalized', fontsize=8)\n",
        "plt.text(90,0.004, r\"RNN: RMS/std = %.2f\" % (rms2a), fontsize=11)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDAuI8HLesyL"
      },
      "source": [
        "##2D scatter plot\n",
        "\n",
        "ypred1a = ypred/1000\n",
        "Y_test1a = Y_test_01/1000\n",
        "\n",
        "plt.hist2d(Y_test1a,ypred1a, bins = 50,norm=mpl.colors.LogNorm())\n",
        "plt.xlim([0, 800])\n",
        "plt.ylim([0, 800])\n",
        "plt.text(500,750, r'6ji4bi@70%', fontsize=8)\n",
        "plt.xlabel('Truth')\n",
        "plt.ylabel('Prediction')\n",
        "plt.plot(Y_test1a,Y_test1a,'k-')\n",
        "plt.colorbar()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgqQvn4evBA"
      },
      "source": [
        "plt.hist2d(Y_test_01/1000, ypred/1000 - Y_test_01/1000, bins = 50,norm=mpl.colors.LogNorm())\n",
        "plt.xlim([0, 800])\n",
        "plt.ylim([-800, 800])\n",
        "plt.text(600,650, r'6ji4bi@70%', fontsize=8)\n",
        "plt.xlabel('Truth')\n",
        "plt.ylabel('Prediction - Truth')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jo_u6rhRew4E"
      },
      "source": [
        "bins_list = [0, 120, 200, 300, 450, 600]\n",
        "\n",
        "x1a = np.array(ypred/1000) # create random data points\n",
        "y1a = np.array(Y_test_01/1000)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "hist1a, xbins1a, ybins1a, im = ax.hist2d(x1a, y1a, bins=bins_list)\n",
        "hist1a *= 1 / hist1a.sum(axis=0)\n",
        "\n",
        "for j in range(len(ybins1a)-1):\n",
        "    for i in range(len(xbins1a)-1):\n",
        "       ax.text(xbins1a[j]+0.5,ybins1a[i]+0.5, r\"%.2f\" %(hist1a.T[j,i]), \n",
        "                color=\"w\", fontweight=\"bold\")\n",
        "plt.xlabel('Truth')\n",
        "plt.ylabel('Prediction')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiVyktdxeyzA"
      },
      "source": [
        "def compute_profile(x, y, nbin=(100,100)):\n",
        "    \n",
        "    # use of the 2d hist by numpy to avoid plotting\n",
        "    h, xe, ye = np.histogram2d(x,y,nbin)\n",
        "    \n",
        "    # bin width\n",
        "    xbinw = xe[1]-xe[0]\n",
        "\n",
        "    # getting the mean and RMS values of each vertical slice of the 2D distribution\n",
        "    # also the x valuse should be recomputed because of the possibility of empty slices\n",
        "    x_array      = []\n",
        "    x_slice_mean = []\n",
        "    x_slice_rms  = []\n",
        "    for i in range(xe.size-1):\n",
        "        yvals = y[ (x>xe[i]) & (x<=xe[i+1]) ]\n",
        "        if yvals.size>0: # do not fill the quanties for empty slices\n",
        "            x_array.append(xe[i]+ xbinw/2)\n",
        "            x_slice_mean.append( yvals.mean())\n",
        "            x_slice_rms.append( yvals.std())\n",
        "    x_array = np.array(x_array)\n",
        "    x_slice_mean = np.array(x_slice_mean)\n",
        "    x_slice_rms = np.array(x_slice_rms)\n",
        "\n",
        "    return x_array, x_slice_mean, x_slice_rms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1VSiWk5e2YB"
      },
      "source": [
        "#compute the profile\n",
        "p_xa, p_meana, p_rmsa = compute_profile(Y_test_01/1000, ypred/1000 - Y_test_01/1000,(50,50))\n",
        "\n",
        "plt.errorbar(p_xa, p_meana, p_rmsa, fmt='_', ecolor='b', color='r')\n",
        "plt.text(600,650, r'6ji4bi@70%', fontsize=8)\n",
        "plt.text(600,500, r' - mean, std', fontsize=10)\n",
        "plt.xlim([0, 800])\n",
        "plt.ylim([-800, 800])\n",
        "plt.xlabel('Truth [GEV]')\n",
        "plt.ylabel('Prediction - Truth')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}